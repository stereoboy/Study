{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* References\n",
    "  * https://handong1587.github.io/deep_learning/2015/10/09/genrative-models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Issues\n",
    "\n",
    "## Generative Adversarial Networks\n",
    "\n",
    "* Source code\n",
    "  * https://github.com/goodfeli/adversarial\n",
    "* Contribution Points\n",
    "  * Induce the concept of Generative Adversarial Networks for replacing traditional Probabilistic Graphical Models\n",
    "  * Prove the existence and the convergence of the solution of it's main objective function\n",
    "<img  src=\"DQU1J420QGGCHE6KIGCI4JQWRA43ASWD.png\"/>\n",
    "\n",
    "<img  src=\"A0DL8S6YCH58V36HT847IS3RBH15QVMO.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks\n",
    "* Source code\n",
    "  * https://github.com/Newmu\n",
    "  * https://github.com/soumith/dcgan.torch\n",
    "  * https://github.com/soumith/ganhacks\n",
    "* Contribution Points\n",
    "  * Make GAN stable to train in most settings\n",
    "    * Replace any pooling layers with \"Strided convolutions(discriminator) and fractional strided convolutions (generator).\n",
    "    * Use batchnorm in both the generator and the discriminator except for the generator output layer and the discriminator input layer.\n",
    "    * Remove fully onnected hidden layers for deeper architecture.\n",
    "    * Use ReLU activation in generator for all layers except for the output, which uses \"tanh\".\n",
    "    * Use LeakyReLU activation in discriminator for all layers.\n",
    "    * Preprocess scaling training images to the range of [-1, 1] for \"tanh\"\n",
    "  * Show the Generators have interesting vector arithmetic properties allowing for easy manipulation of many semantic qualities of generated samples\n",
    "\n",
    "<img  src=\"VYWS76LPVRVUP3EPHTQEVY5H74DQS411.png\"/>\n",
    "\n",
    "<img  src=\"P95PEWQLRYFICYYHT66HB3VJBRRH132S.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\n",
    "* Source code \n",
    "  * https://github.com/openai/InfoGAN\n",
    "<img  src=\"J828LRLIO0YOCG73FVJY5TKQYW9NYWGM.png\"/>  \n",
    "<img  src=\"QV04FGSRJERRBLAVF14613ATV1DYJMAD.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy-based Generative Adversarial Networks\n",
    "* Source code\n",
    "  * Not support the author's official code\n",
    "* Contribution Points\n",
    "  * An Energy-based Formulation for generative adversarial training\n",
    "  * A proof\n",
    "  * A EBGAN framework with the discriminator using an auto-encoder architecture in which the energy is the reconstruction error.\n",
    "  * A set of systematic experiments to explore the set of hyper-parameters and architectural choices that produce good results for EBGANs and conventional GANs.\n",
    "    * EBGAN is more robust\n",
    "    * EBGAN can generate reasonable-looking high-resolution images from 256x256 pixel resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications\n",
    "\n",
    "## Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
    "\n",
    "* $\\hat{x} = G(z)$\n",
    "  * Z is Low Resolution Image, not noise vector Z\n",
    "  * Output X is Super Resolution Image from G\n",
    "* $D(x)$\n",
    "  * X is Ground Truth High Resolution Images or Generated Super Resolution Images\n",
    "* Upscaling using Sub pixel Convlutional Neural Network  \n",
    "> We increase the resolution of the input image with two trained sub-pixel convolution\n",
    " [ D. Rueckert, and Z. Wang. Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network. ]\n",
    "\n",
    "<img  src=\"XR3C47HP252S2GXV23382MNTDGWGWGJ4.png\"/>\n",
    "\n",
    "<img  src=\"QU3Q92FICTH9IO4MOI9XJKWOVM8GHKGU.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation using Adversarial Network\n",
    "\n",
    "* Set Segmentation Networks as Typical G(z)\n",
    "* invent new network D(x) for matching function, If ground truth class map and segmentation map from G(z) is similar -> 1 otherwise 0\n",
    "* New D(x)\n",
    "  * Input: Target image to segment and Class map \n",
    "    * ground truth or Segmented map from G(z) Here z is the target image, There is no noise Z\n",
    "    \n",
    "<img  src=\"PCLHSA29BNAGTNS2562S24SJV7V69JG2.png\"/>\n",
    "<img  src=\"WIFUGPYQLO1QCDVRX972XXBMO5CBOKBR.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Text to Image Synthesis\n",
    "* \n",
    "<img  src=\"DL5OB6I70R2ELF2VL5O5PU44VB06IXTU.png\"/>\n",
    "\n",
    "<img  src=\"CKMCOSPCUBA6Y3HLBNK9QEQT51XDJAKU.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
