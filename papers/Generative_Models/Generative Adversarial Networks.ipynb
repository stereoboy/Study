{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* References\n",
    "  * https://handong1587.github.io/deep_learning/2015/10/09/genrative-models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "* Source code\n",
    "  * https://github.com/goodfeli/adversarial\n",
    "* Contribution Points\n",
    "  * Induce the concept of Generative Adversarial Networks for replacing traditional Probabilistic Graphical Models\n",
    "  * Prove the existence and the convergence of the solution of it's main objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks\n",
    "* Source code\n",
    "  * https://github.com/Newmu\n",
    "  * https://github.com/soumith/dcgan.torch\n",
    "* Contribution Points\n",
    "  * Make GAN stable to train in most settings\n",
    "    * Replace any pooling layers with \"Strided convolutions(discriminator) and fractional strided convolutions (generator).\n",
    "    * Use batchnorm in both the generator and the discriminator except for the generator output layer and the discriminator input layer.\n",
    "    * Remove fully onnected hidden layers for deeper architecture.\n",
    "    * Use ReLU activation in generator for all layers except for the output, which uses \"tanh\".\n",
    "    * Use LeakyReLU activation in discriminator for all layers.\n",
    "    * Preprocess scaling training images to the range of [-1, 1] for \"tanh\"\n",
    "  * Show the Generators have interesting vector arithmetic properties allowing for easy manipulation of many semantic qualities of generated samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\n",
    "* Source code \n",
    "  * https://github.com/openai/InfoGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy-based Generative Adversarial Networks\n",
    "* Source code\n",
    "  * Not support the author's official code\n",
    "* Contribution Points\n",
    "  * An Energy-based Formulation for generative adversarial training\n",
    "  * A proof\n",
    "  * A EBGAN framework with the discriminator using an auto-encoder architecture in which the energy is the reconstruction error.\n",
    "  * A set of systematic experiments to explore the set of hyper-parameters and architectural choices that produce good results for EBGANs and conventional GANs.\n",
    "    * EBGAN is more robust\n",
    "    * EBGAN can generate reasonable-looking high-resolution images from 256x256 pixel resolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
